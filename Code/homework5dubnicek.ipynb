{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /Users/rdubnic2/Documents/lis590dsh/Code\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>genre</th>\n",
       "      <th>reception</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1908</td>\n",
       "      <td>Robins, Elizabeth,</td>\n",
       "      <td>The convert</td>\n",
       "      <td>fiction</td>\n",
       "      <td>elite</td>\n",
       "      <td>looked like decent artisans, but more who bore...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1871</td>\n",
       "      <td>Lytton, Edward Bulwer Lytton,</td>\n",
       "      <td>The coming race</td>\n",
       "      <td>fiction</td>\n",
       "      <td>elite</td>\n",
       "      <td>called the \" Easy Time \" (with which what I ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1872</td>\n",
       "      <td>Butler, Samuel,</td>\n",
       "      <td>Erewhon, or, Over the range</td>\n",
       "      <td>fiction</td>\n",
       "      <td>elite</td>\n",
       "      <td>the curtain ; on this I let it drop and retrea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1900</td>\n",
       "      <td>Barrie, J. M.</td>\n",
       "      <td>Tommy and Grizel</td>\n",
       "      <td>fiction</td>\n",
       "      <td>elite</td>\n",
       "      <td>at you !\" he said. \"Dear eyes, \" said she. \"Th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1873</td>\n",
       "      <td>Ritchie, Anne Thackeray,</td>\n",
       "      <td>Old Kensington</td>\n",
       "      <td>fiction</td>\n",
       "      <td>elite</td>\n",
       "      <td>furious; I have not dared tell her, poor creat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   date                         author                        title    genre  \\\n",
       "0  1908             Robins, Elizabeth,                  The convert  fiction   \n",
       "1  1871  Lytton, Edward Bulwer Lytton,              The coming race  fiction   \n",
       "2  1872                Butler, Samuel,  Erewhon, or, Over the range  fiction   \n",
       "3  1900                  Barrie, J. M.             Tommy and Grizel  fiction   \n",
       "4  1873       Ritchie, Anne Thackeray,               Old Kensington  fiction   \n",
       "\n",
       "  reception                                               text  \n",
       "0     elite  looked like decent artisans, but more who bore...  \n",
       "1     elite  called the \" Easy Time \" (with which what I ma...  \n",
       "2     elite  the curtain ; on this I let it drop and retrea...  \n",
       "3     elite  at you !\" he said. \"Dear eyes, \" said she. \"Th...  \n",
       "4     elite  furious; I have not dared tell her, poor creat...  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, csv, math, random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "cwd = os.getcwd()\n",
    "print('Current working directory: ' + cwd + '\\n')\n",
    "      \n",
    "relativepath = os.path.join('..', 'data', 'weekfour', 'poefic.csv')\n",
    "poefic = pd.read_csv(relativepath)\n",
    "poefic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 5 homework.\n",
    "\n",
    "In class, we built a classifier that detected Trump's authorship of tweets from his account. Repeat that work for the poefic dataset. Build a classifier that distinguishes poetry from fiction. \n",
    "\n",
    "Almost all the code you need is in the notebook we used in class. Copy functions from that notebook and paste them here, altering them as necessary so that they use the metadata available in the poefic frame. Include a function that does five-fold crossvalidation. Play around with different settings of p (the number of features included in the model) to see how high you can get the accuracy.\n",
    "\n",
    "Then, at the end of the notebook, write a short paragraph of commentary. How much accuracy do you get? Why do you think that accuracy for this classification task is higher or lower than it was on the Trump tweet data? (You might want to inspect the data itself, using Excel or a text editor.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>genre</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>looked like decent artisans, but more who bore...</td>\n",
       "      <td>fiction</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>called the \" Easy Time \" (with which what I ma...</td>\n",
       "      <td>fiction</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the curtain ; on this I let it drop and retrea...</td>\n",
       "      <td>fiction</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>at you !\" he said. \"Dear eyes, \" said she. \"Th...</td>\n",
       "      <td>fiction</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>furious; I have not dared tell her, poor creat...</td>\n",
       "      <td>fiction</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text    genre  fold\n",
       "0  looked like decent artisans, but more who bore...  fiction     4\n",
       "1  called the \" Easy Time \" (with which what I ma...  fiction     1\n",
       "2  the curtain ; on this I let it drop and retrea...  fiction     4\n",
       "3  at you !\" he said. \"Dear eyes, \" said she. \"Th...  fiction     1\n",
       "4  furious; I have not dared tell her, poor creat...  fiction     0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def poefic_test(a_data_frame, rowidx):\n",
    "    if 'poetry' in a_data_frame['genre'][rowidx]:\n",
    "        return 'poetry'\n",
    "    elif 'fiction' in a_data_frame['genre'][rowidx]:\n",
    "        return 'fiction'\n",
    "    else:\n",
    "        return 'other'\n",
    "    \n",
    "poefic_text = poefic['text']\n",
    "\n",
    "genre = []\n",
    "fold = []\n",
    "for idx in poefic.index:\n",
    "    genre.append(poefic_test(poefic, idx))\n",
    "    fold.append(random.sample(list(range(5)), 1)[0])\n",
    "genre = pd.Series(genre, index = poefic.index)\n",
    "fold = pd.Series(fold, index = poefic.index)\n",
    "\n",
    "pf_df = pd.concat([poefic_text, genre, fold], axis = 1)\n",
    "pf_df.columns = ['text', 'genre', 'fold']\n",
    "\n",
    "# limit the dataframe to columns with either android or iphone;\n",
    "# exclude 'other'\n",
    "pf_df = pf_df[(pf_df['genre'] == 'poetry') | (pf_df['genre'] == 'fiction')]\n",
    "pf_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set includes 819\n",
      "Test set includes 208\n"
     ]
    }
   ],
   "source": [
    "testset = pf_df[pf_df['fold'] == 4]\n",
    "trainingset = pf_df[pf_df['fold'] != 4]\n",
    "print('Training set includes ' + str(trainingset.shape[0]))\n",
    "print('Test set includes ' + str(testset.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize(astring):\n",
    "    ''' Breaks a string into words, and counts them.\n",
    "    Designed so it strips punctuation and lowercases everything,\n",
    "    but doesn't separate hashtags and at-signs.\n",
    "    '''\n",
    "    wordcounts = Counter()\n",
    "    # create a counter to hold the counts\n",
    "    \n",
    "    tokens = astring.split()\n",
    "    for t in tokens:\n",
    "        word = t.strip(',.!?:;-â€”()<>[]/\"\\'').lower()\n",
    "        wordcounts[word] += 1\n",
    "        \n",
    "    return wordcounts\n",
    "\n",
    "def create_vocab(seq_of_strings, n):\n",
    "    ''' Given a sequence of text snippets, this function\n",
    "    returns the n most common words. We'll use this to\n",
    "    create a limited 'vocabulary'.\n",
    "    '''\n",
    "    vocab = Counter()\n",
    "    for astring in seq_of_strings:\n",
    "        counts = tokenize(astring)\n",
    "        vocab = vocab + counts\n",
    "    topn = [x[0] for x in vocab.most_common(n)]\n",
    "    return topn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "android = poetry\n",
      "iphone = fiction\n",
      "more positive means more likely poetry\n",
      "more negative means more likely fiction\n",
      "genre\n",
      "fiction    290\n",
      "poetry     529\n",
      "Name: text, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fiction</th>\n",
       "      <th>poetry</th>\n",
       "      <th>all_prob</th>\n",
       "      <th>fiction_prob</th>\n",
       "      <th>poetry_prob</th>\n",
       "      <th>fiction_norm</th>\n",
       "      <th>poetry_norm</th>\n",
       "      <th>log_fiction</th>\n",
       "      <th>log_poetry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>17489</td>\n",
       "      <td>37399</td>\n",
       "      <td>0.120523</td>\n",
       "      <td>0.100245</td>\n",
       "      <td>0.133114</td>\n",
       "      <td>0.831751</td>\n",
       "      <td>1.104477</td>\n",
       "      <td>-0.184222</td>\n",
       "      <td>0.099372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>12196</td>\n",
       "      <td>22072</td>\n",
       "      <td>0.075245</td>\n",
       "      <td>0.069906</td>\n",
       "      <td>0.078561</td>\n",
       "      <td>0.929040</td>\n",
       "      <td>1.044064</td>\n",
       "      <td>-0.073603</td>\n",
       "      <td>0.043120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>10460</td>\n",
       "      <td>23659</td>\n",
       "      <td>0.074918</td>\n",
       "      <td>0.059955</td>\n",
       "      <td>0.084210</td>\n",
       "      <td>0.800279</td>\n",
       "      <td>1.124020</td>\n",
       "      <td>-0.222795</td>\n",
       "      <td>0.116912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of</th>\n",
       "      <td>9080</td>\n",
       "      <td>15490</td>\n",
       "      <td>0.053951</td>\n",
       "      <td>0.052045</td>\n",
       "      <td>0.055134</td>\n",
       "      <td>0.964687</td>\n",
       "      <td>1.021928</td>\n",
       "      <td>-0.035951</td>\n",
       "      <td>0.021691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>9277</td>\n",
       "      <td>11732</td>\n",
       "      <td>0.046131</td>\n",
       "      <td>0.053175</td>\n",
       "      <td>0.041758</td>\n",
       "      <td>1.152678</td>\n",
       "      <td>0.905192</td>\n",
       "      <td>0.142088</td>\n",
       "      <td>-0.099608</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     fiction  poetry  all_prob  fiction_prob  poetry_prob  fiction_norm  \\\n",
       "the    17489   37399  0.120523      0.100245     0.133114      0.831751   \n",
       "       12196   22072  0.075245      0.069906     0.078561      0.929040   \n",
       "and    10460   23659  0.074918      0.059955     0.084210      0.800279   \n",
       "of      9080   15490  0.053951      0.052045     0.055134      0.964687   \n",
       "to      9277   11732  0.046131      0.053175     0.041758      1.152678   \n",
       "\n",
       "     poetry_norm  log_fiction  log_poetry  \n",
       "the     1.104477    -0.184222    0.099372  \n",
       "        1.044064    -0.073603    0.043120  \n",
       "and     1.124020    -0.222795    0.116912  \n",
       "of      1.021928    -0.035951    0.021691  \n",
       "to      0.905192     0.142088   -0.099608  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('android = poetry')\n",
    "print('iphone = fiction')\n",
    "print('more positive means more likely poetry')\n",
    "print('more negative means more likely fiction')\n",
    "\n",
    "def categorize(df, rowidx):\n",
    "    if df.loc[rowidx, 'genre'] == 'poetry':\n",
    "        return 'poetry'\n",
    "    elif df.loc[rowidx, 'genre'] == 'fiction':\n",
    "        return 'fiction'\n",
    "    else:\n",
    "        print('error: neither fiction nor poetry')\n",
    "        return 'other'\n",
    "\n",
    "def get_priors(df):\n",
    "    source_counts = df.groupby('genre').count()['text']\n",
    "    print(source_counts)\n",
    "    poetry_odds = source_counts['poetry'] / source_counts['fiction']\n",
    "    fiction_odds = source_counts['fiction'] / source_counts['poetry']\n",
    "    return math.log(poetry_odds), math.log(fiction_odds)\n",
    "\n",
    "def train_nb_model(df, p):\n",
    "    vocab = create_vocab(df['text'], p)\n",
    "    vocabset = set(vocab)\n",
    "    # we make a set because membership-checking is faster\n",
    "    # in sets; but we also hold onto the list, which is ordered\n",
    "    \n",
    "    poetry_prior, fiction_prior = get_priors(df)\n",
    "    \n",
    "    poetry_counts = Counter()\n",
    "    fiction_counts = Counter()\n",
    "    \n",
    "    for i in df.index:\n",
    "        work = df['text'][i]\n",
    "        work_counts = tokenize(work)\n",
    "        category = categorize(df, i)\n",
    "        if category == 'fiction':\n",
    "            fiction_counts = fiction_counts + work_counts\n",
    "        elif category == 'poetry':\n",
    "            poetry_counts = poetry_counts + work_counts\n",
    "    \n",
    "    # Now let's organize these Counters into a DataFrame\n",
    "    \n",
    "    fiction = pd.Series(1, index = vocab)\n",
    "    poetry = pd.Series(1, index = vocab)\n",
    "    # notice initializing to 1 -- Laplacian smoothing\n",
    "    \n",
    "    for word, count in poetry_counts.items():\n",
    "        if word in vocabset:\n",
    "            poetry[word] += count\n",
    "    \n",
    "    for word, count in fiction_counts.items():\n",
    "        if word in vocabset:\n",
    "            fiction[word] += count\n",
    "    \n",
    "    all_prob = (fiction + poetry) / (np.sum(fiction) + np.sum(poetry))\n",
    "    \n",
    "    fiction_prob = fiction / np.sum(fiction)\n",
    "    poetry_prob = poetry / np.sum(poetry)\n",
    "    \n",
    "    # note that when we sum up the fiction and poetry\n",
    "    # columns, we are also summing up all the Laplacian 1's\n",
    "    # we initially added to them\n",
    "    \n",
    "    model = pd.concat([fiction, poetry, all_prob, \n",
    "                       fiction_prob, poetry_prob], axis = 1) \n",
    "        \n",
    "    model.columns = ['fiction', 'poetry', 'all_prob', 'fiction_prob', 'poetry_prob']\n",
    "    \n",
    "    # The next step is unnecessary, and will not be found in\n",
    "    # most published versions of naive Bayes. I'm providing it\n",
    "    # because it may help you understand the logic of the\n",
    "    # algorithm.\n",
    "    \n",
    "    model['fiction_norm'] = fiction_prob / all_prob\n",
    "    model['poetry_norm'] = poetry_prob / all_prob\n",
    "    \n",
    "    \n",
    "    model['log_fiction'] = [math.log(x) for x in model['fiction_norm']]\n",
    "    model['log_poetry'] = [math.log(x) for x in model['poetry_norm']]\n",
    "    return vocab, poetry_prior, fiction_prior, model\n",
    "\n",
    "vocab, poetry_prior, fiction_prior, model = train_nb_model(trainingset, 75)\n",
    "model.head()\n",
    "\n",
    "# print(poetry_prior, fiction_prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "def apply_model(vocab, poetry_prior, fiction_prior, model, testset):\n",
    "    right = 0\n",
    "    wrong = 0\n",
    "    vocabset = set(vocab)\n",
    "    odds_poe = []\n",
    "    odds_fic = []\n",
    "\n",
    "    for i in testset.index:\n",
    "        odds_poetry = poetry_prior\n",
    "        odds_fiction = fiction_prior\n",
    "        lit = testset['text'][i]\n",
    "        lit_counts = tokenize(lit)\n",
    "        for word, count in lit_counts.items():\n",
    "            if word not in vocabset:\n",
    "                continue\n",
    "            odds_poetry += model.loc[word, 'log_poetry']\n",
    "            odds_fiction += model.loc[word, 'log_fiction']\n",
    "            \n",
    "        if odds_poetry > odds_fiction:\n",
    "            prediction = 'poetry'\n",
    "        else:\n",
    "            prediction = 'fiction'\n",
    "        \n",
    "        odds_poe.append(odds_poetry)\n",
    "        odds_fic.append(odds_fiction)\n",
    "\n",
    "        reality = categorize(testset, i)\n",
    "        if reality != 'poetry' and reality != 'fiction':\n",
    "            continue\n",
    "        elif prediction == reality:\n",
    "            right += 1\n",
    "        else:\n",
    "            wrong += 1\n",
    "\n",
    "    print(\"Got \" + str(right) + \" rows right, and \" + str(wrong) + \" wrong.\")\n",
    "    accuracy = (right / (wrong + right)) * 100\n",
    "    print(\"Accuracy was {0:.2f}%\".format(accuracy))\n",
    "    \n",
    "    resultset = testset.copy()\n",
    "    resultset['odds_poetry'] = odds_poe\n",
    "    resultset['odds_fiction'] = odds_fic\n",
    "    resultset = resultset.sort_values(by = 'odds_poetry')\n",
    "    \n",
    "    return resultset, accuracy\n",
    "\n",
    "newtestset = apply_model(vocab, poetry_prior, fiction_prior, model, testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# newtestset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def five_fold_cross_valid(df, p):\n",
    "    accuracies = []\n",
    "    for i in range(5):\n",
    "        pf_df_test_set = pf_df[pf_df['fold'] == i]\n",
    "        pf_df_training_set = pf_df[pf_df['fold'] != i] \n",
    "        vocab, poetry_prior, fiction_prior, model = train_nb_model(pf_df_training_set, p)\n",
    "        pf_df_test_set, accuracy = apply_model(vocab, poetry_prior, fiction_prior, model, testset)\n",
    "        accuracies.append(accuracy)\n",
    "    avg_acc = print('Average accuracy is ', round(sum(accuracies)/len(accuracies),2), '%')\n",
    "    return avg_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genre\n",
      "fiction    273\n",
      "poetry     531\n",
      "Name: text, dtype: int64\n",
      "Got 201 rows right, and 7 wrong.\n",
      "Accuracy was 96.63%\n",
      "genre\n",
      "fiction    285\n",
      "poetry     545\n",
      "Name: text, dtype: int64\n",
      "Got 201 rows right, and 7 wrong.\n",
      "Accuracy was 96.63%\n",
      "genre\n",
      "fiction    293\n",
      "poetry     529\n",
      "Name: text, dtype: int64\n",
      "Got 201 rows right, and 7 wrong.\n",
      "Accuracy was 96.63%\n",
      "genre\n",
      "fiction    295\n",
      "poetry     538\n",
      "Name: text, dtype: int64\n",
      "Got 201 rows right, and 7 wrong.\n",
      "Accuracy was 96.63%\n",
      "genre\n",
      "fiction    290\n",
      "poetry     529\n",
      "Name: text, dtype: int64\n",
      "Got 199 rows right, and 9 wrong.\n",
      "Accuracy was 95.67%\n",
      "Average accuracy is  96.44 %\n"
     ]
    }
   ],
   "source": [
    "five_fold_cross_valid(pf_df, 2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brief Analysis of Results\n",
    "This function is far more accurate than for the trump data (I was never able to get much above 75% accuracy, for some reason). After looking at the data, it's still not totally clear to me, but I can hazard a guess based on the age of the data. Both the poetry and fiction, being all from 1920 and before, are likely to be more homogenous within each category. Thought the size of the dataset is prohibitive to inspect each work individually, it's possible that this dataset is more rigid in structure and style than our modern writing could be. Perhaps even more impactful is the length of each work in the dataset. When classifying fiction or poetry on this data, we are given a whole lot more than 140 characters per example. Though the trump data has around 5000 entries and over 38,000 words, this data likely has over 11,000 more words in it, allowing for more training data for the algorithm. With p values in the range of 2,000, I was able to push average accuracy after the five-fold cross validation test to over 96%."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
