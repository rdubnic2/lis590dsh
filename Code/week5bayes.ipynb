{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 5: A Naive Bayes classifier\n",
    "\n",
    "Suppose President Trump gets savvy, and realizes that people can use the Android/iPhone distinction to separate his tweets from the the tweets of aides. He starts using an iPhone too. Now, how will we distinguish tweets really authored by the President?\n",
    "\n",
    "Well, one thing we can do is train a classifier to predict authorship using the text itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /Users/rdubnic2/Documents/lis590dsh/Code\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>text</th>\n",
       "      <th>favorited</th>\n",
       "      <th>favoriteCount</th>\n",
       "      <th>replyToSN</th>\n",
       "      <th>created</th>\n",
       "      <th>truncated</th>\n",
       "      <th>replyToSID</th>\n",
       "      <th>id</th>\n",
       "      <th>replyToUID</th>\n",
       "      <th>statusSource</th>\n",
       "      <th>screenName</th>\n",
       "      <th>retweetCount</th>\n",
       "      <th>isRetweet</th>\n",
       "      <th>retweeted</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>My economic policy speech will be carried live...</td>\n",
       "      <td>False</td>\n",
       "      <td>9214</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-08-08 15:20:44</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>762669882571980801</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>3107</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Join me in Fayetteville, North Carolina tomorr...</td>\n",
       "      <td>False</td>\n",
       "      <td>6981</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-08-08 13:28:20</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>762641595439190016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>2390</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>#ICYMI: \"Will Media Apologize to Trump?\" https...</td>\n",
       "      <td>False</td>\n",
       "      <td>15724</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-08-08 00:05:54</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>762439658911338496</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>6691</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Michael Morell, the lightweight former Acting ...</td>\n",
       "      <td>False</td>\n",
       "      <td>19837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-08-07 23:09:08</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>762425371874557952</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>6402</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>The media is going crazy. They totally distort...</td>\n",
       "      <td>False</td>\n",
       "      <td>34051</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-08-07 21:31:46</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>762400869858115588</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>11717</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1  \\\n",
       "0           0             1   \n",
       "1           1             2   \n",
       "2           2             3   \n",
       "3           3             4   \n",
       "4           4             5   \n",
       "\n",
       "                                                text favorited  favoriteCount  \\\n",
       "0  My economic policy speech will be carried live...     False           9214   \n",
       "1  Join me in Fayetteville, North Carolina tomorr...     False           6981   \n",
       "2  #ICYMI: \"Will Media Apologize to Trump?\" https...     False          15724   \n",
       "3  Michael Morell, the lightweight former Acting ...     False          19837   \n",
       "4  The media is going crazy. They totally distort...     False          34051   \n",
       "\n",
       "  replyToSN              created truncated  replyToSID                  id  \\\n",
       "0       NaN  2016-08-08 15:20:44     False         NaN  762669882571980801   \n",
       "1       NaN  2016-08-08 13:28:20     False         NaN  762641595439190016   \n",
       "2       NaN  2016-08-08 00:05:54     False         NaN  762439658911338496   \n",
       "3       NaN  2016-08-07 23:09:08     False         NaN  762425371874557952   \n",
       "4       NaN  2016-08-07 21:31:46     False         NaN  762400869858115588   \n",
       "\n",
       "   replyToUID                                       statusSource  \\\n",
       "0         NaN  <a href=\"http://twitter.com/download/android\" ...   \n",
       "1         NaN  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "2         NaN  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "3         NaN  <a href=\"http://twitter.com/download/android\" ...   \n",
       "4         NaN  <a href=\"http://twitter.com/download/android\" ...   \n",
       "\n",
       "        screenName  retweetCount isRetweet retweeted  longitude  latitude  \n",
       "0  realDonaldTrump          3107     False     False        NaN       NaN  \n",
       "1  realDonaldTrump          2390     False     False        NaN       NaN  \n",
       "2  realDonaldTrump          6691     False     False        NaN       NaN  \n",
       "3  realDonaldTrump          6402     False     False        NaN       NaN  \n",
       "4  realDonaldTrump         11717     False     False        NaN       NaN  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, csv, math, random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "cwd = os.getcwd()\n",
    "print('Current working directory: ' + cwd + '\\n')\n",
    "      \n",
    "relativepath = '/Users/rdubnic2/Documents/lis590dsh/Data/trump.csv'\n",
    "trump = pd.read_csv(relativepath)\n",
    "trump.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's simplify the Trump dataframe. We only need three columns:\n",
    "\n",
    "1. Text of the tweet\n",
    "2. Source = Android or iphone\n",
    "3. A random number 0-4 that we'll use to divide the dataset into five 'folds'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My economic policy speech will be carried live...</td>\n",
       "      <td>android</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Join me in Fayetteville, North Carolina tomorr...</td>\n",
       "      <td>iphone</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#ICYMI: \"Will Media Apologize to Trump?\" https...</td>\n",
       "      <td>iphone</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Michael Morell, the lightweight former Acting ...</td>\n",
       "      <td>android</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The media is going crazy. They totally distort...</td>\n",
       "      <td>android</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text   source  fold\n",
       "0  My economic policy speech will be carried live...  android     3\n",
       "1  Join me in Fayetteville, North Carolina tomorr...   iphone     3\n",
       "2  #ICYMI: \"Will Media Apologize to Trump?\" https...   iphone     0\n",
       "3  Michael Morell, the lightweight former Acting ...  android     1\n",
       "4  The media is going crazy. They totally distort...  android     0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def trump_test(a_data_frame, rowidx):\n",
    "    if 'iphone' in a_data_frame['statusSource'][rowidx]:\n",
    "        return 'iphone'\n",
    "    elif 'android' in a_data_frame['statusSource'][rowidx]:\n",
    "        return 'android'\n",
    "    else:\n",
    "        return 'other'\n",
    "    \n",
    "tweet_text = trump['text']\n",
    "\n",
    "source = []\n",
    "fold = []\n",
    "for idx in trump.index:\n",
    "    source.append(trump_test(trump, idx))\n",
    "    fold.append(random.sample(list(range(5)), 1)[0])\n",
    "source = pd.Series(source, index = trump.index)\n",
    "fold = pd.Series(fold, index = trump.index)\n",
    "\n",
    "tdf = pd.concat([tweet_text, source, fold], axis = 1)\n",
    "tdf.columns = ['text', 'source', 'fold']\n",
    "\n",
    "# limit the dataframe to columns with either android or iphone;\n",
    "# exclude 'other'\n",
    "tdf = tdf[(tdf['source'] == 'android') | (tdf['source'] == 'iphone')]\n",
    "tdf.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to divide the dataset into a training set and a test set. This is easily done using the \"folds.\" We select one fold as our test set and use all the others as a training set.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set includes 1113\n",
      "Test set includes 277\n"
     ]
    }
   ],
   "source": [
    "testset = tdf[tdf['fold'] == 4]\n",
    "trainingset = tdf[tdf['fold'] != 4]\n",
    "print('Training set includes ' + str(trainingset.shape[0]))\n",
    "print('Test set includes ' + str(testset.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Thank you Windham, New Hampshire! #TrumpPence1...</td>\n",
       "      <td>iphone</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Anybody whose mind \"SHORT CIRCUITS\" is not fit...</td>\n",
       "      <td>android</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>President Obama should ask the DNC about how t...</td>\n",
       "      <td>iphone</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Great meeting all of you. This group knocked o...</td>\n",
       "      <td>iphone</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Thank you Jacksonville, Florida!\\n#MakeAmerica...</td>\n",
       "      <td>iphone</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text   source  fold\n",
       "6   Thank you Windham, New Hampshire! #TrumpPence1...   iphone     4\n",
       "11  Anybody whose mind \"SHORT CIRCUITS\" is not fit...  android     4\n",
       "24  President Obama should ask the DNC about how t...   iphone     4\n",
       "28  Great meeting all of you. This group knocked o...   iphone     4\n",
       "30  Thank you Jacksonville, Florida!\\n#MakeAmerica...   iphone     4"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need some basic text-wrangling functions that we've used before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize(astring):\n",
    "    ''' Breaks a string into words, and counts them.\n",
    "    Designed so it strips punctuation and lowercases everything,\n",
    "    but doesn't separate hashtags and at-signs.\n",
    "    '''\n",
    "    wordcounts = Counter()\n",
    "    # create a counter to hold the counts\n",
    "    \n",
    "    tokens = astring.split()\n",
    "    for t in tokens:\n",
    "        word = t.strip(',.!?:;-—()<>[]/\"\\'').lower()\n",
    "        wordcounts[word] += 1\n",
    "        \n",
    "    return wordcounts\n",
    "\n",
    "def create_vocab(seq_of_strings, n):\n",
    "    ''' Given a sequence of text snippets, this function\n",
    "    returns the n most common words. We'll use this to\n",
    "    create a limited 'vocabulary'.\n",
    "    '''\n",
    "    vocab = Counter()\n",
    "    for astring in seq_of_strings:\n",
    "        counts = tokenize(astring)\n",
    "        vocab = vocab + counts\n",
    "    topn = [x[0] for x in vocab.most_common(n)]\n",
    "    return topn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can actually write functions that build a Naive Bayes model. ```train_nb_model``` is the central function here. It calls the other two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source\n",
      "android    600\n",
      "iphone     513\n",
      "Name: text, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neg</th>\n",
       "      <th>pos</th>\n",
       "      <th>all_prob</th>\n",
       "      <th>neg_prob</th>\n",
       "      <th>pos_prob</th>\n",
       "      <th>neg_norm</th>\n",
       "      <th>pos_norm</th>\n",
       "      <th>log_neg</th>\n",
       "      <th>log_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>165</td>\n",
       "      <td>497</td>\n",
       "      <td>0.029308</td>\n",
       "      <td>0.019233</td>\n",
       "      <td>0.035477</td>\n",
       "      <td>0.656247</td>\n",
       "      <td>1.210512</td>\n",
       "      <td>-0.421219</td>\n",
       "      <td>0.191043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>136</td>\n",
       "      <td>262</td>\n",
       "      <td>0.017620</td>\n",
       "      <td>0.015853</td>\n",
       "      <td>0.018702</td>\n",
       "      <td>0.899698</td>\n",
       "      <td>1.061424</td>\n",
       "      <td>-0.105696</td>\n",
       "      <td>0.059611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>90</td>\n",
       "      <td>300</td>\n",
       "      <td>0.017266</td>\n",
       "      <td>0.010491</td>\n",
       "      <td>0.021415</td>\n",
       "      <td>0.607602</td>\n",
       "      <td>1.240302</td>\n",
       "      <td>-0.498236</td>\n",
       "      <td>0.215355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>104</td>\n",
       "      <td>210</td>\n",
       "      <td>0.013901</td>\n",
       "      <td>0.012123</td>\n",
       "      <td>0.014990</td>\n",
       "      <td>0.872057</td>\n",
       "      <td>1.078351</td>\n",
       "      <td>-0.136901</td>\n",
       "      <td>0.075433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in</th>\n",
       "      <td>127</td>\n",
       "      <td>180</td>\n",
       "      <td>0.013591</td>\n",
       "      <td>0.014804</td>\n",
       "      <td>0.012849</td>\n",
       "      <td>1.089197</td>\n",
       "      <td>0.945376</td>\n",
       "      <td>0.085441</td>\n",
       "      <td>-0.056172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     neg  pos  all_prob  neg_prob  pos_prob  neg_norm  pos_norm   log_neg  \\\n",
       "the  165  497  0.029308  0.019233  0.035477  0.656247  1.210512 -0.421219   \n",
       "to   136  262  0.017620  0.015853  0.018702  0.899698  1.061424 -0.105696   \n",
       "and   90  300  0.017266  0.010491  0.021415  0.607602  1.240302 -0.498236   \n",
       "a    104  210  0.013901  0.012123  0.014990  0.872057  1.078351 -0.136901   \n",
       "in   127  180  0.013591  0.014804  0.012849  1.089197  0.945376  0.085441   \n",
       "\n",
       "      log_pos  \n",
       "the  0.191043  \n",
       "to   0.059611  \n",
       "and  0.215355  \n",
       "a    0.075433  \n",
       "in  -0.056172  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def categorize(df, rowidx): # 'df' is 'data frame'\n",
    "    if df.loc[rowidx, 'source'] == 'android':\n",
    "        return 'positive' # can change 'positive' or 'negative' to be whatever labels you want (e.g. fiction, nonfiction, iphone, android)\n",
    "    elif df.loc[rowidx, 'source'] == 'iphone': # pandas function to find the object's row, then check a given column for a classification\n",
    "        return 'negative'\n",
    "    else:\n",
    "        print('error: neither iphone nor android')\n",
    "        return 'other'\n",
    "\n",
    "def get_priors(df):\n",
    "    source_counts = df.groupby('source').count()['text']\n",
    "    print(source_counts)\n",
    "    positive_odds = source_counts['android'] / source_counts['iphone']\n",
    "    negative_odds = source_counts['iphone'] / source_counts['android']\n",
    "    return math.log(positive_odds), math.log(negative_odds)\n",
    "\n",
    "def train_nb_model(df, p): # p is the number of words you're using in your model, the portion of the total vocabulary\n",
    "    vocab = create_vocab(df['text'], p)\n",
    "    vocabset = set(vocab)\n",
    "    # we make a set because membership-checking is faster\n",
    "    # in sets; but we also hold onto the list, which is ordered\n",
    "    \n",
    "    positive_prior, negative_prior = get_priors(df)\n",
    "    \n",
    "    positive_counts = Counter()\n",
    "    negative_counts = Counter()\n",
    "    \n",
    "    for i in df.index:\n",
    "        tweet = df['text'][i]\n",
    "        tweet_counts = tokenize(tweet)\n",
    "        category = categorize(df, i)\n",
    "        if category == 'negative':\n",
    "            negative_counts = negative_counts + tweet_counts\n",
    "        elif category == 'positive':\n",
    "            positive_counts = positive_counts + tweet_counts\n",
    "    \n",
    "    # Now let's organize these Counters into a DataFrame\n",
    "    \n",
    "    negative = pd.Series(1, index = vocab)\n",
    "    positive = pd.Series(1, index = vocab)\n",
    "    # notice initializing to 1 -- Laplacian smoothing\n",
    "    \n",
    "    for word, count in positive_counts.items():\n",
    "        if word in vocabset:\n",
    "            positive[word] += count\n",
    "    \n",
    "    for word, count in negative_counts.items():\n",
    "        if word in vocabset:\n",
    "            negative[word] += count\n",
    "    \n",
    "    all_prob = (negative + positive) / (np.sum(negative) + np.sum(positive))\n",
    "    \n",
    "    negative_prob = negative / np.sum(negative)\n",
    "    positive_prob = positive / np.sum(positive)\n",
    "    \n",
    "    # note that when we sum up the negative and positive\n",
    "    # columns, we are also summing up all the Laplacian 1's\n",
    "    # we initially added to them\n",
    "    \n",
    "    model = pd.concat([negative, positive, all_prob, \n",
    "                       negative_prob, positive_prob], axis = 1) \n",
    "        \n",
    "    model.columns = ['neg', 'pos', 'all_prob', 'neg_prob', 'pos_prob']\n",
    "    \n",
    "    # The next step is unnecessary, and will not be found in\n",
    "    # most published versions of naive Bayes. I'm providing it\n",
    "    # because it may help you understand the logic of the\n",
    "    # algorithm.\n",
    "    \n",
    "    model['neg_norm'] = negative_prob / all_prob\n",
    "    model['pos_norm'] = positive_prob / all_prob\n",
    "    \n",
    "    \n",
    "    model['log_neg'] = [math.log(x) for x in model['neg_norm']] # using log to control for long floats, which are hard to handle\n",
    "    model['log_pos'] = [math.log(x) for x in model['pos_norm']]\n",
    "    return vocab, positive_prior, negative_prior, model\n",
    "\n",
    "vocab, positive_prior, negative_prior, model = train_nb_model(trainingset, 2350)\n",
    "model.head() \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we're using logarithms of the probabilities, so that we can just add them up. Our priors are logarithms, too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Thank you Windham, New Hampshire! #TrumpPence1...</td>\n",
       "      <td>iphone</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Anybody whose mind \"SHORT CIRCUITS\" is not fit...</td>\n",
       "      <td>android</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>President Obama should ask the DNC about how t...</td>\n",
       "      <td>iphone</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Great meeting all of you. This group knocked o...</td>\n",
       "      <td>iphone</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Thank you Jacksonville, Florida!\\n#MakeAmerica...</td>\n",
       "      <td>iphone</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text   source  fold\n",
       "6   Thank you Windham, New Hampshire! #TrumpPence1...   iphone     4\n",
       "11  Anybody whose mind \"SHORT CIRCUITS\" is not fit...  android     4\n",
       "24  President Obama should ask the DNC about how t...   iphone     4\n",
       "28  Great meeting all of you. This group knocked o...   iphone     4\n",
       "30  Thank you Jacksonville, Florida!\\n#MakeAmerica...   iphone     4"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1566538100453768 -0.15665381004537685\n"
     ]
    }
   ],
   "source": [
    "print(positive_prior, negative_prior)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's write a function that applies a given model to a given testset. It will have lots of arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 221 rows right, and 56 wrong.\n",
      "Accuracy was 79.78%\n"
     ]
    }
   ],
   "source": [
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "def apply_model(vocab, positive_prior, negative_prior, model, testset):\n",
    "    right = 0\n",
    "    wrong = 0\n",
    "    vocabset = set(vocab)\n",
    "    odds_pos = []\n",
    "    odds_neg = []\n",
    "\n",
    "    for i in testset.index:\n",
    "        odds_positive = positive_prior\n",
    "        odds_negative = negative_prior\n",
    "        tweet = testset['text'][i]\n",
    "        tweet_counts = tokenize(tweet)\n",
    "        for word, count in tweet_counts.items():\n",
    "            if word not in vocabset:\n",
    "                continue\n",
    "            odds_positive += model.loc[word, 'log_pos']\n",
    "            odds_negative += model.loc[word, 'log_neg']\n",
    "            \n",
    "        if odds_positive > odds_negative:\n",
    "            prediction = 'positive'\n",
    "        else:\n",
    "            prediction = 'negative'\n",
    "        \n",
    "        odds_pos.append(odds_positive)\n",
    "        odds_neg.append(odds_negative)\n",
    "\n",
    "        reality = categorize(testset, i)\n",
    "        if reality != 'positive' and reality != 'negative':\n",
    "            continue\n",
    "        elif prediction == reality:\n",
    "            right += 1\n",
    "        else:\n",
    "            wrong += 1\n",
    "\n",
    "    print(\"Got \" + str(right) + \" rows right, and \" + str(wrong) + \" wrong.\")\n",
    "    accuracy = (right / (wrong + right)) * 100\n",
    "    print(\"Accuracy was {0:.2f}%\".format(accuracy))\n",
    "    \n",
    "    resultset = testset.copy()\n",
    "    resultset['odds_positive'] = odds_pos\n",
    "    resultset['odds_negative'] = odds_neg\n",
    "    resultset = resultset.sort_values(by = 'odds_positive')\n",
    "    \n",
    "    return resultset, accuracy\n",
    "\n",
    "newtestset, accuracy = apply_model(vocab, positive_prior, \n",
    "                         negative_prior, model, testset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ```apply_model``` function returns a version of the test set with two new columns. The dataframe is sorted by the (ascending) odds of being in the positive class, so we can find the \"Trumpiest\" and \"least Trumpy\" tweets by saying ```.tail()``` or ```.head()``` respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Thank you Windham, New Hampshire! #TrumpPence1...</td>\n",
       "      <td>iphone</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Anybody whose mind \"SHORT CIRCUITS\" is not fit...</td>\n",
       "      <td>android</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>President Obama should ask the DNC about how t...</td>\n",
       "      <td>iphone</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Great meeting all of you. This group knocked o...</td>\n",
       "      <td>iphone</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Thank you Jacksonville, Florida!\\n#MakeAmerica...</td>\n",
       "      <td>iphone</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text   source  fold\n",
       "6   Thank you Windham, New Hampshire! #TrumpPence1...   iphone     4\n",
       "11  Anybody whose mind \"SHORT CIRCUITS\" is not fit...  android     4\n",
       "24  President Obama should ask the DNC about how t...   iphone     4\n",
       "28  Great meeting all of you. This group knocked o...   iphone     4\n",
       "30  Thank you Jacksonville, Florida!\\n#MakeAmerica...   iphone     4"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1.\n",
    "\n",
    "To start with, just play around with the functions above in order to find a value of ```p``` (number of parameters in the model) that roughly maximizes accuracy on the test set.\n",
    "\n",
    "What accuracy do you get if you train a model on the whole ```tdf``` data frame, and also apply it to ```tdf``` as a whole?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source\n",
      "android    600\n",
      "iphone     513\n",
      "Name: text, dtype: int64\n",
      "Got 221 rows right, and 56 wrong.\n",
      "Accuracy was 79.78%\n"
     ]
    }
   ],
   "source": [
    "vocab, positive_prior, negative_prior, model = train_nb_model(trainingset, 2280)\n",
    "model.head() \n",
    "\n",
    "newtestset, accuracy = apply_model(vocab, positive_prior, \n",
    "                         negative_prior, model, testset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2.\n",
    "\n",
    "Write a function that *cross-validates* a modeling strategy by applying it successively to five different training sets and testing it on five different test sets.\n",
    "\n",
    "This is called \"five-fold crossvalidation.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def five_fold_cross_valid(tdf, p):\n",
    "    accuracies = []\n",
    "    for i in range(5):\n",
    "        tdf_test_set = tdf[tdf['fold'] == i]\n",
    "        tdf_training_set = tdf[tdf['fold'] != i] \n",
    "        vocab, positive_prior, negative_prior, model = train_nb_model(tdf_training_set, p)\n",
    "        tdf_test_set, accuracy = apply_model(vocab, positive_prior, negative_prior, model, testset)\n",
    "        accuracies.append(accuracy)\n",
    "    avg_acc = print('Average accuracy is ', round(sum(accuracies)/len(accuracies),2), '%')\n",
    "    return avg_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source\n",
      "android    599\n",
      "iphone     510\n",
      "Name: text, dtype: int64\n",
      "Got 250 rows right, and 27 wrong.\n",
      "Accuracy was 90.25%\n",
      "source\n",
      "android    622\n",
      "iphone     497\n",
      "Name: text, dtype: int64\n",
      "Got 252 rows right, and 25 wrong.\n",
      "Accuracy was 90.97%\n",
      "source\n",
      "android    594\n",
      "iphone     488\n",
      "Name: text, dtype: int64\n",
      "Got 249 rows right, and 28 wrong.\n",
      "Accuracy was 89.89%\n",
      "source\n",
      "android    633\n",
      "iphone     504\n",
      "Name: text, dtype: int64\n",
      "Got 248 rows right, and 29 wrong.\n",
      "Accuracy was 89.53%\n",
      "source\n",
      "android    600\n",
      "iphone     513\n",
      "Name: text, dtype: int64\n",
      "Got 222 rows right, and 55 wrong.\n",
      "Accuracy was 80.14%\n",
      "Average accuracy is  88.16 %\n"
     ]
    }
   ],
   "source": [
    "five_fold_cross_valid(tdf, 1900)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3 (probably, for homework).\n",
    "\n",
    "Do all this for the poefic dataset, trying to distinguish poetry from fiction. Create a new notebook. Copy functions as needed in order to build a naive Bayes classifier and run five-fold crossvalidation.\n",
    "\n",
    "How much accuracy do you get? Why do you think that accuracy is higher or lower than it was on the Trump tweet data? (You might want to inspect the data itself, using Excel or a text editor.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
