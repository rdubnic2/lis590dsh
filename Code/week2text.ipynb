{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading text\n",
    "\n",
    "In this notebook, we'll practice reading text files and transforming them into word counts.\n",
    "\n",
    "In doing that we'll also practice some basic structural aspects of Python.\n",
    "\n",
    "* I/O using absolute and relative file paths\n",
    "* Two new data structures: the dictionary and Counter.\n",
    "* The idea of a *module*.\n",
    "\n",
    "We will eventually learn how to abbreviate some of these operations with the ```nltk``` module. But I think it's useful to do it slowly at first, so you get a good grasp on Python's underlying data structures.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Reading text\n",
    "\n",
    "### a. absolute and relative paths\n",
    "\n",
    "When you're working at the command line, your location in the folder hierarchy is represented by a series of directory names separated by slashes. If you're in OS X, for instance and you type\n",
    "\n",
    "    > pwd\n",
    "\n",
    "you'll get a string that represents the current \"working directory,\" like,\n",
    "\n",
    "    /Users/tunder/Dropbox/courses/2017datasci/code\n",
    "\n",
    "In Windows, the slashes go the other way, so this might be\n",
    "\n",
    "    > cd\n",
    "    C:\\Users\\tunder\\Dropbox\\courses\\2017datasci\\code\n",
    "   \n",
    "This is called a *path.* In this case, it's a path to a directory. If we wanted to name a specific file in the directory, we could provide the path plus a filename, such as\n",
    "\n",
    "    /Users/tunder/Dropbox/courses/2017datasci/code/ex2readingtext.ipynb\n",
    "   \n",
    "which is the location of this file on my machine.\n",
    "\n",
    "These are *absolute paths* because they start from the root of the folder hierarchy and contain all the information needed to locate the file. In writing this notebook, however, I don't know your user name, or exactly where you've put our course folder on your machine. So I'm going to try to use *relative paths* to point to files.\n",
    "\n",
    "In this case, for instance, I know that your python notebooks are in a folder named ```code```, and your data files are living in a folder next to that one, named ```data```. So if I wanted to point to a file in the ```data``` folder, I might say,\n",
    "\n",
    "    ../data/exampledata.txt\n",
    "\n",
    "You'll recall that ```cd ..``` moves you up a level in the folder hierarchy. So the function of the ```..``` in the relative path is to move us up a level in the hierarchy, to the parent course folder. Then ```data``` moves us back down to the data folder, and ```exampledata.txt``` is an (imaginary) data file.\n",
    "\n",
    "The only problem with this system is that it won't work on Windows. The slashes would need to go the other way. So let's make use of a special Python tool that can get around that hassle, the *module* ```os```. A module is a collection of pieces of Python code. If you want to use one or more of those pieces, you can *import* the module. The ```os``` module contains tools that can be used to manipulate your operating system. So, for instance,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/firstcorpus/ShelleyFrankenstein.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "relativepath = os.path.join('..', 'data', 'firstcorpus', 'ShelleyFrankenstein.txt')\n",
    "print(relativepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result you get by running that code will depend on the operating system you're running. If you run it under Windows, you'll get slashes pointing the other direction.\n",
    "\n",
    "Now let's use this relative path to open a file\n",
    "\n",
    "### b. text input\n",
    "\n",
    "When you're reading or writing from a file, it's important to close the file when you're done. There are ways to do that manually, but generally it's simpler and more reliable to use Python's *context manager,* an indented block of code that begins with the key word ```with```. For instance,\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Project Gutenberg EBook of Frankenstein, by Mary W. Shelley\n",
      "\n",
      "continue? \n",
      "\n",
      "\n",
      "continue? y\n",
      "This eBook is for the use of anyone anywhere at no cost and with\n",
      "\n",
      "continue? y\n",
      "almost no restrictions whatsoever.  You may copy it, give it away or\n",
      "\n",
      "continue? y\n",
      "re-use it under the terms of the Project Gutenberg License included\n",
      "\n",
      "continue? y\n",
      "with this eBook or online at www.gutenberg.org\n",
      "\n",
      "continue? y\n",
      "\n",
      "\n",
      "continue? y\n",
      "\n",
      "\n",
      "continue? n\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "relativepath = os.path.join('..', 'data', 'firstcorpus', 'ShelleyFrankenstein.txt')\n",
    "\n",
    "list_of_lines = list()\n",
    "\n",
    "with open(relativepath, mode = 'r', encoding = 'utf-8') as f:\n",
    "    for line in f:\n",
    "        print(line)\n",
    "        user_wish = input('continue? ')\n",
    "        if user_wish == 'n':\n",
    "            break\n",
    "        else:\n",
    "            list_of_lines.append(line)\n",
    "        \n",
    "print(len(list_of_lines))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you run that code, it should allow you to step through the Project Gutenberg text of *Frankenstein* line by line. The process will continue each time you hit ```Enter``` and stop only if your reply to ```continue?``` is ```n```.\n",
    "\n",
    "Take a moment to think about how this works, following the program line by line.\n",
    "\n",
    "The ```with``` statement opens the file identified by ```relativepath```. The mode is set to ```r```, for read. Other possible modes are ```w```rite and ```a```ppend. It puts the file in a file object named ```f```. Then we can simply use a ```for``` loop to step through the file line by line. The loop will proceed through the whole file unless we ```break``` it. The ```break``` statement always escapes from the most recently-enclosing loop.\n",
    "\n",
    "Once you've escaped from the loop, the next statement will execute. In this case it simply prints the number of lines you gathered. If you wanted to gather them all at once, you wouldn't need a loop. Instead you could just say\n",
    "\n",
    "    list_of_lines == f.readlines()\n",
    "\n",
    "### c. tokenizing text.\n",
    "\n",
    "Right now we're looking at the file as a list of lines. But in reality, to do data science on text, we usually want to count individual words — or, word-like objects (numbers, etc). We can call these objects generally *tokens,* and the process of transforming text into a list of tokens is called *tokenizing.*\n",
    "\n",
    "In the last class we met the 'split' function, which gets us part of the way there, relying on the fact that English words are generally divided by white space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'Project', 'Gutenberg', 'EBook', 'of', 'Frankenstein,', 'by', 'Mary', 'W.', 'Shelley']\n"
     ]
    }
   ],
   "source": [
    "firstline = 'The Project Gutenberg EBook of Frankenstein, by Mary W. Shelley'\n",
    "tokens = firstline.split()\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a list of tokens, but not exactly a list of words. You'll notice, for instance, that there's punctuation attached to \"Frankenstein,\" and \"W.\"\n",
    "\n",
    "But still it's good enough to give us a rough estimate of the number of words in a file.\n",
    "\n",
    "### Exercise 1. Counting tokens.\n",
    "\n",
    "Use the code we developed above to count the total number of tokens in *Frankenstein.* For the moment, we'll define a token simply as a sequence of characters separated by whitespace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file contained 80989 tokens.\n"
     ]
    }
   ],
   "source": [
    "# Code for Exercise 1.\n",
    "\n",
    "import os\n",
    "relativepath = os.path.join('..', 'data', 'firstcorpus', 'ShelleyFrankenstein.txt')\n",
    "\n",
    "number_of_tokens = 0\n",
    "\n",
    "with open(relativepath, mode = 'r', encoding = 'utf-8') as f:\n",
    "    for line in f:\n",
    "        tokens = line.split() # split line into tokens\n",
    "        number_of_tokens += len(tokens) # update running number of tokens with new number from previous line\n",
    "        # print(number_of_tokens)\n",
    "        # what goes here? \n",
    "        # you need two lines\n",
    "\n",
    "print('The file contained {0} tokens.'.format(number_of_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that strings have a ```format``` method that can be used when you need to provide variables to \"fill in\" certain \"blanks.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d. the glob module.\n",
    "\n",
    "Suppose we wanted to know the number of words for all the files in the ```firstcorpus``` folder. Instead of writing a separate piece of code for each one, we would probably use a loop. So we need,\n",
    "\n",
    "* first, a list of all the files in the folder, and\n",
    "* then, for each file, do the same thing we did above for *Frankenstein*\n",
    "\n",
    "Try this in\n",
    "\n",
    "### Exercise 2: reading all the files in a folder.\n",
    "\n",
    "I'll give you the code to get a list of files in a folder. This makes use of the ```glob``` module. Then, once we have a list of paths to all the files, you can take it from there, building a new ```for``` loop and pasting some code from above. Count the words for each file, and print the number of words next to the file path.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/firstcorpus/*.txt\n",
      "['../data/firstcorpus/AustenPride.txt', '../data/firstcorpus/DickinsonPoems.txt', '../data/firstcorpus/EliotPrufrock.txt', '../data/firstcorpus/ShelleyFrankenstein.txt', '../data/firstcorpus/StokerDracula.txt', '../data/firstcorpus/WordsworthLyrical.txt']\n",
      "../data/firstcorpus/AustenPride.txt contains 124592 tokens.\n",
      "../data/firstcorpus/DickinsonPoems.txt contains 10546 tokens.\n",
      "../data/firstcorpus/EliotPrufrock.txt contains 6871 tokens.\n",
      "../data/firstcorpus/ShelleyFrankenstein.txt contains 80989 tokens.\n",
      "../data/firstcorpus/StokerDracula.txt contains 164428 tokens.\n",
      "../data/firstcorpus/WordsworthLyrical.txt contains 24497 tokens.\n"
     ]
    }
   ],
   "source": [
    "# Code for exercise 2.\n",
    "\n",
    "import os, glob\n",
    "relativepath = os.path.join('..', 'data', 'firstcorpus', '*.txt')\n",
    "print(relativepath)\n",
    "textfilepaths = glob.glob(relativepath)\n",
    "print(textfilepaths)\n",
    "for file in textfilepaths: \n",
    "    num_tok = 0\n",
    "    with open(file, mode = 'r', encoding = 'utf-8') as f:\n",
    "        for line in f:\n",
    "            tokens = line.split()\n",
    "            num_tok += len(tokens)\n",
    "        print('{0} contains {1} tokens.'.format(file,num_tok))\n",
    "\n",
    "## Here's where you need to add code.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Word frequencies.\n",
    "\n",
    "Counting the *total* number of words in a text doesn't tell us very much. Usually when we're working with text, we'll want to know the frequencies of *specific* words. \n",
    "\n",
    "When we start counting words, we're going to need to produce a data structure that's a little more complex than a list. We need a *mapping* between words and numbers. So, for instance, here are some frequencies in this paragraph:\n",
    "\n",
    "    a : 4\n",
    "    here : 1\n",
    "    going : 1\n",
    "    so : 1\n",
    "    for : 1\n",
    "    to : 2\n",
    "    words : 2\n",
    "\n",
    "When we need to represent a *mapping* in Python, we usually create a *dictionary.* A dictionary maps a key to a value. So, for instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'banana': 'yellow', 'apple': 'red'}\n",
      "yellow\n"
     ]
    }
   ],
   "source": [
    "colors = dict()\n",
    "colors['apple'] = 'red'\n",
    "colors['banana'] = 'yellow'\n",
    "print(colors)\n",
    "print(colors['banana'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting a key in square brackets after the dictionary name gets you the value for that key. But notice what happens if you try a key that hasn't been entered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'guava'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-867d7278035b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcolors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'guava'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 'guava'"
     ]
    }
   ],
   "source": [
    "colors['guava']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice also that the brackets have to be square. If you use parentheses, Python will think you're trying to *call* a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "colors('apple')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can count word frequencies by mapping each word to the number of times it has occurred in the text. We iterate through the text, and each time we see a word, we add one to its value in the wordcount dictionary. The only problem is, we can't add one if it's not yet in the dictionary! We would get a key error, as seen above. So when you use a dictionary to count things, you have to check whether the key is already in the dictionary. An if-else statement is handy here. Follow the logic below. Try deleting the line\n",
    "\n",
    "    w = w.lower().strip(',.* ')\n",
    "    \n",
    "and see how the results change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "paragraph = \"When we start counting words, we're going to need to produce a data structure that's a little more complex than a list. We need a *mapping* between words and numbers. So, for instance, here are some frequencies in this paragraph:\"\n",
    "wordcounts = dict()\n",
    "for w in paragraph.split():\n",
    "    w = w.lower().strip(',.* ')\n",
    "    if w not in wordcounts:\n",
    "        wordcounts[w] = 1\n",
    "    else:\n",
    "        wordcounts[w] = wordcounts[w] + 1\n",
    "\n",
    "# You cannot iterate through a dictionary quite as simply as if it were\n",
    "# a list. Instead of individual elements, you want (key, value) pairs.\n",
    "# To get them you can iterate through the dictionary's ```items``` method.\n",
    "# Note that a method has to be followed by () parentheses, even when it\n",
    "# takes no argument.\n",
    "\n",
    "for word, count in sorted(wordcounts.items()):\n",
    "    print(word + \" : \" + str(count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To save ourselves the labor of checking whether a word is in the dictionary yet, we can use a ```Counter,``` a convenient data structure in the ```collections``` module. Instead of returning a KeyError when you ask for a key that doesn't exist yet, a Counter returns 0. So you can skip the if-else and just start by adding one to the default value of 0.\n",
    "\n",
    "Another nice feature of ```Counters``` is that they have a ```most_common()``` method that gives you a sorted list of the keys with the highest values. In the code below, we use that feature to identify the five most frequent words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "paragraph = \"When we start counting words, we're going to need to produce a data structure that's a little more complex than a list. We need a *mapping* between words and numbers. So, for instance, here are some frequencies in this paragraph:\"\n",
    "wordcounts = Counter()\n",
    "for w in paragraph.split():\n",
    "    w = w.lower().strip(',.* ')\n",
    "    wordcounts[w] = wordcounts[w] + 1\n",
    "\n",
    "topfive = wordcounts.most_common(5)\n",
    "print(topfive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that each element of the list ```topfive``` is a pair of items enclosed in parentheses. This is actually an example of a new data structure, a **tuple.** A tuple is basically an immutable list. You can't append to it, but there are some nice tricks you can perform, especially something called *tuple packing*, which allows you to turn a series of items separated by a comma into a single object, and then unpack it again into multiple objects. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a_tuple = ('need', 2)\n",
    "word, frequency = a_tuple\n",
    "print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3. Word frequencies.\n",
    "\n",
    "Adapt your code from Exercise 1 so that, instead of just counting the total number of words in *Frankenstein,* you identify the most common 100 words. Include a line like\n",
    "\n",
    "    w = w.lower().strip(',.*\"-—() ')\n",
    "\n",
    "so that we don't count words separately when they're only distinguished by capitalization or punctuation.\n",
    "\n",
    "Put the list of ```most_common()``` words in a list called ```tophundred```. Print the first ten items from ```tophundred```.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Code for Exercise 3.\n",
    "import os, glob\n",
    "relativepath = os.path.join('..', 'data', 'firstcorpus', 'StokerDracula.txt')\n",
    "print(relativepath)\n",
    "textfilepaths = glob.glob(relativepath)\n",
    "print(textfilepaths)\n",
    "from collections import Counter # import Counter module to use it in all namespaces\n",
    "for file in textfilepaths: # read in each file\n",
    "    wordc = Counter() # initialize wordc variable as a Counter object\n",
    "    with open(file, mode = 'r', encoding = 'utf-8') as f: # open each file and read in as variable f\n",
    "        for lines in f: # read in each line\n",
    "            tokens = lines.split() # split lines into words, delineated by white space\n",
    "            for w in tokens: # split words from lines\n",
    "                w = w.lower().strip(',.* ()[]') # make all words lower case, and strip non-letter/number characters from each word\n",
    "                wordc[w] += 1 # append word count dictionary with an updated value for each key\n",
    "                \n",
    "tophundred = wordc.most_common(100) # use Counter to assign top 100 most common words to variable 'tophundred'\n",
    "print(tophundred[0:10]) # print the top 10 of the tophundred variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. A bit of exploratory data visualization.\n",
    "\n",
    "Now we can start to explore the data, to get a sense of its shape. One simple thing to do is to plot the raw word counts for the first hundred words. To do this we need to use a module called matplotlib.\n",
    "\n",
    "Python has a lot of pretty and elegant features. Its syntax for visualization is not really one of them. We have to say ```%matplotlib inline``` as a kind of magic word that permits graphs to be displayed in a Jupyter notebook. Then we import a specific subset of matplotlib called \"pyplot.\" We rename it ```plt```, for a shorter convenience name. Then we pass ```plt```'s plot method a list of numbers, which it treats as the y axis values. (If x values aren't provided, it assumes by default that we want a sequence of integers, which in this case is exactly what we do want.) Finally, we have to say ```plt.show()``` to make the image actually appear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This crude visualization is already revealing something pretty fundamental about the way word frequencies behave. Try the same exercise with *Pride and Prejudice.* (You'll have to rerun Exercise 3, using a different file name, and then re-run the visualization code above.)\n",
    "\n",
    "You have just discovered [Zipf's Law.](https://en.wikipedia.org/wiki/Zipf's_law)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "justcounts = [x[1] for x in tophundred]\n",
    "plt.plot(justcounts)\n",
    "plt.ylabel('raw count of occurrences')\n",
    "plt.xlabel('ordinal position of word in ranked list')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rules for creating visualizations are pretty hard to systematize, because there are an endless number of knobs that people may want to tune to control the appearance of an image. You might want to browse through [an initial pyplot tutorial,](http://matplotlib.org/users/pyplot_tutorial.html) but I have to confess that in practice I learn these things in an ad-hoc fashion: I usually Google around to learn a particular trick when I have a project that requires it.\n",
    "\n",
    "There are a few general patterns worth knowing, however. For instance, you can change the plot from a line graph to a series of data points by providing a code that indicates the color and shape for points. The first character determines the color, the second the shape of the point.\n",
    "\n",
    "    ro = red circles\n",
    "    bo = blue circles\n",
    "    k+ = black crosses\n",
    "    g-- = green dashes\n",
    "    ms = magenta squares\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.xlim((-5, 105))\n",
    "# that option defines the limits of the x axis; here I've\n",
    "# set it manually to give us extra space on either side\n",
    "\n",
    "plt.plot(justcounts, 'cs')\n",
    "# let's use cyan squares!\n",
    "\n",
    "plt.ylabel('raw count of occurrences')\n",
    "plt.xlabel('ordinal position of word in ranked list')\n",
    "\n",
    "plt.grid(True)\n",
    "# turning on grid lines\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4: if you have extra time.\n",
    "\n",
    "Play around a bit with the code above to change the color and shape of the points, the axis labels, and the limits of the y or x axes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
