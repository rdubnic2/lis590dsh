{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 4: Applying Dunning's log-likelihood to 19c poetry\n",
    "\n",
    "I've put my \"solutions\" to in-class exercises on the Moodle, except for Exercise 2, which has become our homework assignment. \n",
    "\n",
    "## Problem 1.\n",
    "\n",
    "Find 25 words that are overrepresented in poetry reviewed by elite 19c magazines, as compared to other works of poetry that didn't get reviewed in those venues. Also list 25 words that are overrepresented in poetry that didn't get reviewed.\n",
    "\n",
    "To do this, you'll need to copy over some of the functions from our Week 4 exercises, and also copy over the code from our in-class Exercise #1, editing it so that it divides the corpus.\n",
    "\n",
    "Here's some code to get us started. I load some modules we're likely to need, and then load the ```poefic``` corpus.\n",
    "\n",
    "Then I filter the ```poefic``` DataFrame to have only poetry. I'm doing this for two reasons. The first is that I'm a little concerned that the size of the data is posing a problem on some computers. The other, more immediate, reason is that this dataset only has an even distribution of the \"reception\" variable in poetry. (Almost all the fiction I gave you was reviewed in elite venues.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "def tokenize(astring):\n",
    "    ''' Breaks a string into words, and counts them.\n",
    "    Designed so it strips punctuation and lowercases everything,\n",
    "    but doesn't separate hashtags and at-signs.\n",
    "    '''\n",
    "    wordcounts = Counter()\n",
    "    # create a counter to hold the counts\n",
    "    \n",
    "    tokens = astring.split()\n",
    "    for t in tokens:\n",
    "        word = t.strip(',.!?:;-—()<>[]/\"\\'').lower()\n",
    "        wordcounts[word] += 1\n",
    "        \n",
    "    return wordcounts\n",
    "\n",
    "def addcounters(counter2add, countersum):\n",
    "    ''' Adds all the counts in counter2add to countersum.\n",
    "    Because Counters(like dictionaries) are mutable, it\n",
    "    doesn't need to return anything.\n",
    "    '''\n",
    "    \n",
    "    for key, value in counter2add.items():\n",
    "        countersum[key] += value\n",
    "\n",
    "def create_vocab(seq_of_strings, n):\n",
    "    ''' Given a sequence of text snippets, this function\n",
    "    returns the n most common words. We'll use this to\n",
    "    create a limited 'vocabulary'.\n",
    "    '''\n",
    "    vocab = Counter()\n",
    "    for astring in seq_of_strings:\n",
    "        counts = tokenize(astring)\n",
    "        addcounters(counts, vocab)\n",
    "    topn = [x[0] for x in vocab.most_common(n)]\n",
    "    return topn\n",
    "\n",
    "# Let's test the vocabulary function.\n",
    "# vocab = create_vocab(trump['text'], 4000)\n",
    "# vocab[0:10]\n",
    "\n",
    "def logodds(countsA, countsB, word):\n",
    "    ''' Straightforward.\n",
    "    '''\n",
    "    \n",
    "    odds = (countsA[word] + 1) / (countsB[word] + 1)\n",
    "    \n",
    "    # Why do we add 1 on both sides? Two reasons. The hacky one is \n",
    "    # that otherwise we'll get a division-by-zero error whenever\n",
    "    # word isn't present in countsB. The more principled reason\n",
    "    # is that this technique (called Laplacian smoothing) tends\n",
    "    # to reduce the dramatic disproportion likely to be found in\n",
    "    # very rare words.\n",
    "    \n",
    "    return math.log(odds)\n",
    "\n",
    "def signed_dunnings(countsA, totalA, countsB, totalB, word):\n",
    "    ''' Less straightforward. This function calculates a signed (+1 / -1)\n",
    "    version of Dunning's log likelihood. Intuitively, this is a number \n",
    "    that gets larger as the frequency of the word in our two corpora\n",
    "    diverges from its EXPECTED frequency -- i.e., the frequency it would\n",
    "    have if it were equally distributed over both. But it also tends to get\n",
    "    larger as the raw frequency of the word increases.\n",
    "    \n",
    "    Note that this function requires two additional arguments:\n",
    "    the total number of words in A and B. We could calculate that inside\n",
    "    the function, but it's faster to calculate it just once, outside the function.\n",
    "    \n",
    "    Also note: the strict definition of Dunnings has no 'sign': it gets bigger\n",
    "    whether a word is overrepresented in A or B. I've edited that so that Dunnings\n",
    "    is positive if overrepresented in A, and negative if overrepresented in B.\n",
    "    '''\n",
    "    if word not in countsA and word not in countsB:\n",
    "        return 0\n",
    "    \n",
    "    # the raw frequencies of this word in our two corpora\n",
    "    # still doing a little Laplacian smoothing here\n",
    "    a = countsA[word] + 0.1\n",
    "    b = countsB[word] + 0.1\n",
    "    \n",
    "    # now let's calculate the expected number of times this\n",
    "    # word would occur in both if the frequency were constant\n",
    "    # across both\n",
    "    overallfreq = (a + b) / (totalA + totalB)\n",
    "    expectedA = totalA * overallfreq\n",
    "    expectedB = totalB * overallfreq\n",
    "    \n",
    "    # and now the Dunning's formula\n",
    "    dunning = 2 * ((a * math.log(a / expectedA)) + (b * math.log(b / expectedB)))\n",
    "    \n",
    "    if a < expectedA:\n",
    "        return -dunning\n",
    "    else:   \n",
    "        return dunning\n",
    "\n",
    "# a set of common words is often useful\n",
    "stopwords = {'a', 'an', 'are', 'and', 'but', 'or', 'that', 'this', 'so', \n",
    "             'all', 'at', 'if', 'in', 'i', 'is', 'was', 'by', 'of', 'to', \n",
    "             'the', 'be', 'you', 'were'}\n",
    "\n",
    "# finally, one more function: given a list of tuples like\n",
    "# testlist = [(10, 'ten'), (2000, 'two thousand'), (0, 'zero'), (-1, 'neg one'), (8, 'eight')]\n",
    "# we're going to want to sort them and print the top n and bottom n\n",
    "\n",
    "def headandtail(tuplelist, n):\n",
    "    tuplelist.sort(reverse = True)\n",
    "    print(\"TOP VALUES:\")\n",
    "    for i in range(n):\n",
    "        print(tuplelist[i][1], tuplelist[i][0])\n",
    "    \n",
    "    print()\n",
    "    print(\"BOTTOM VALUES:\")\n",
    "    lastindex = len(tuplelist) - 1\n",
    "    for i in range(lastindex, lastindex - n, -1):\n",
    "        print(tuplelist[i][1], tuplelist[i][0])\n",
    "        \n",
    "# headandtail(testlist, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /Users/rdubnic2/Documents/lis590dsh/Code\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>genre</th>\n",
       "      <th>reception</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>1835</td>\n",
       "      <td>Browning, Robert,</td>\n",
       "      <td>Paracelsus</td>\n",
       "      <td>poetry</td>\n",
       "      <td>remove</td>\n",
       "      <td>Paracelsus. We 154 PARACELSUS [BOOK III Not ea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>1833</td>\n",
       "      <td>Browning, Robert,</td>\n",
       "      <td>Pauline</td>\n",
       "      <td>poetry</td>\n",
       "      <td>remove</td>\n",
       "      <td>all, I sought How best life’s end might be att...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>1855</td>\n",
       "      <td>Arnold, Matthew,</td>\n",
       "      <td>Poems</td>\n",
       "      <td>poetry</td>\n",
       "      <td>elite</td>\n",
       "      <td>grace, and Wisdom be too proud To halve a lodg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>1867</td>\n",
       "      <td>Arnold, Matthew,</td>\n",
       "      <td>New poems</td>\n",
       "      <td>poetry</td>\n",
       "      <td>elite</td>\n",
       "      <td>from the West was then in shade. Ah ! now 'tis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>1861</td>\n",
       "      <td>Mangum, A. W.</td>\n",
       "      <td>The holy shield</td>\n",
       "      <td>poetry</td>\n",
       "      <td>vulgar</td>\n",
       "      <td>happy hgme which he had exchange d for the ten...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     date             author            title   genre reception  \\\n",
       "359  1835  Browning, Robert,       Paracelsus  poetry    remove   \n",
       "360  1833  Browning, Robert,          Pauline  poetry    remove   \n",
       "361  1855   Arnold, Matthew,            Poems  poetry     elite   \n",
       "362  1867   Arnold, Matthew,        New poems  poetry     elite   \n",
       "363  1861      Mangum, A. W.  The holy shield  poetry    vulgar   \n",
       "\n",
       "                                                  text  \n",
       "359  Paracelsus. We 154 PARACELSUS [BOOK III Not ea...  \n",
       "360  all, I sought How best life’s end might be att...  \n",
       "361  grace, and Wisdom be too proud To halve a lodg...  \n",
       "362  from the West was then in shade. Ah ! now 'tis...  \n",
       "363  happy hgme which he had exchange d for the ten...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, csv, math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "cwd = os.getcwd()\n",
    "print('Current working directory: ' + cwd + '\\n')\n",
    "      \n",
    "relativepath = os.path.join('..', 'data', 'weekfour', 'poefic.csv')\n",
    "poefic = pd.read_csv(relativepath)\n",
    "\n",
    "# FILTERING BY ROW TO GET ONLY THE POETRY\n",
    "poefic = poefic[poefic['genre'] == 'poetry']\n",
    "# equivalent to\n",
    "    # poefic = poefic.loc[poefic['genre] == poetry, : ]\n",
    "poefic.head()\n",
    "\n",
    "# poefic_noelite = poefic[poefic['reception'] != 'elite']\n",
    "# poefic_noelite.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A small digression about the code above**\n",
    "\n",
    "It's worth dwelling for a moment on the statement that does filtering by row. Notice that if you index a pandas DataFrame with a single string, like ```poefic['genre']```, you get a column. But if you generate a series of Boolean values, and use *that* to index the DataFrame, like so,\n",
    "\n",
    "```poefic[poefic['genre'] == 'poetry']```\n",
    "\n",
    "You'll be selecting *rows* where the series has a value ```True.```\n",
    "\n",
    "If it's not clear what I mean by \"generating a series of Boolean values,\" look at the result of the cell below. (You can delete the cell below when you're working on the homework; this is all a digression.) Notice also, in the code above, that you can also use the ```.loc``` method to specify rows and columns at the same time if you want to. In this case I haven't specified a column for ```.loc``` to select, the ``` : ``` after the comma is a way of saying \"all the columns.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "359     False\n",
       "360     False\n",
       "361      True\n",
       "362      True\n",
       "363     False\n",
       "364     False\n",
       "365     False\n",
       "366     False\n",
       "367      True\n",
       "368      True\n",
       "369     False\n",
       "370     False\n",
       "371      True\n",
       "372      True\n",
       "373      True\n",
       "374     False\n",
       "375      True\n",
       "376     False\n",
       "377      True\n",
       "378      True\n",
       "379     False\n",
       "380      True\n",
       "381     False\n",
       "382     False\n",
       "383      True\n",
       "384      True\n",
       "385      True\n",
       "386      True\n",
       "387      True\n",
       "388     False\n",
       "        ...  \n",
       "997     False\n",
       "998      True\n",
       "999      True\n",
       "1000     True\n",
       "1001     True\n",
       "1002    False\n",
       "1003     True\n",
       "1004    False\n",
       "1005    False\n",
       "1006     True\n",
       "1007     True\n",
       "1008     True\n",
       "1009     True\n",
       "1010     True\n",
       "1011     True\n",
       "1012    False\n",
       "1013    False\n",
       "1014    False\n",
       "1015    False\n",
       "1016     True\n",
       "1017    False\n",
       "1018    False\n",
       "1019    False\n",
       "1020    False\n",
       "1021    False\n",
       "1022     True\n",
       "1023    False\n",
       "1024    False\n",
       "1025    False\n",
       "1026    False\n",
       "Name: reception, dtype: bool"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poefic['reception'] == 'elite'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total vocab =  38254\n",
      "Total unique words in vocab = 38254\n",
      "Total vocab minus stop words =  38231\n",
      "Total number of rows in Poefic dataset =  668\n",
      "Words in ignored texts: 365\n",
      "Total words in poems reviewed =  24967\n",
      "Total words in poems not reviewed =  25192\n",
      "Total word count =  36116\n",
      "    FOR DUNNINGS:\n",
      "TOP VALUES:\n",
      "i 167.76726952723084\n",
      " 135.90025363219797\n",
      "and 134.8437370701729\n",
      "her 123.63473157251235\n",
      "she 113.56243768397769\n",
      "the 107.96082971148235\n",
      "a 78.53690586579944\n",
      "wind 58.45393239811642\n",
      "pb 53.26838289299076\n",
      "isis 44.96097587392186\n",
      "face 43.95188980741705\n",
      "me 41.36231391262953\n",
      "old 39.284928591681904\n",
      "out 38.38242829901128\n",
      "osiris 38.017244905451996\n",
      "o 35.806851198561844\n",
      "grey 35.41520615776817\n",
      "white 35.32557111412548\n",
      "man 35.23672856824297\n",
      "eyes 34.25347474466608\n",
      "you 31.480921256959988\n",
      "into 31.280510012192934\n",
      "down 30.225223816065693\n",
      "my 28.67224996707995\n",
      "ye 28.631183360844503\n",
      "\n",
      "BOTTOM VALUES:\n",
      "jesus -59.69241425151195\n",
      "our -43.113445711577924\n",
      "emma -38.71232907582554\n",
      "reign -32.34866408346143\n",
      "tis -29.6479991419439\n",
      "ho -28.635640003070375\n",
      "we -28.370156707657316\n",
      "rosamond -26.56296427051764\n",
      "prayer -26.26452981658057\n",
      "laura -25.195801654819785\n",
      "philomel -24.401918692611527\n",
      "herodias -23.82918515928674\n",
      "join -23.766478160508942\n",
      "saviour -23.766478160508942\n",
      "mornia's -21.097849423537397\n",
      "lend -20.979095728236047\n",
      "home -20.49411988998432\n",
      "complete -20.01006696018858\n",
      "apache -19.733290418404714\n",
      "journal -19.300264579876345\n",
      "aulus -18.369604700863206\n",
      "diuk -18.369604700863206\n",
      "santaclaus -18.369604700863206\n",
      "lyteria -17.00692038741852\n",
      "foes -16.623335701576423\n",
      "    FOR DUNNINGS, STOP WORDS REMOVED:\n",
      "TOP VALUES:\n",
      " 135.90025363219797\n",
      "her 123.63473157251235\n",
      "she 113.56243768397769\n",
      "wind 58.45393239811642\n",
      "pb 53.26838289299076\n",
      "isis 44.96097587392186\n",
      "face 43.95188980741705\n",
      "me 41.36231391262953\n",
      "old 39.284928591681904\n",
      "out 38.38242829901128\n",
      "osiris 38.017244905451996\n",
      "o 35.806851198561844\n",
      "grey 35.41520615776817\n",
      "white 35.32557111412548\n",
      "man 35.23672856824297\n",
      "eyes 34.25347474466608\n",
      "into 31.280510012192934\n",
      "down 30.225223816065693\n",
      "my 28.67224996707995\n",
      "ye 28.631183360844503\n",
      "shadow 28.547310180210637\n",
      "typhon 28.3074243781077\n",
      "said 27.667836864544583\n",
      "eleanore 26.92182550643518\n",
      "willie 26.86794357894358\n",
      "\n",
      "BOTTOM VALUES:\n",
      "jesus -59.69241425151195\n",
      "our -43.113445711577924\n",
      "emma -38.71232907582554\n",
      "reign -32.34866408346143\n",
      "tis -29.6479991419439\n",
      "ho -28.635640003070375\n",
      "we -28.370156707657316\n",
      "rosamond -26.56296427051764\n",
      "prayer -26.26452981658057\n",
      "laura -25.195801654819785\n",
      "philomel -24.401918692611527\n",
      "herodias -23.82918515928674\n",
      "join -23.766478160508942\n",
      "saviour -23.766478160508942\n",
      "mornia's -21.097849423537397\n",
      "lend -20.979095728236047\n",
      "home -20.49411988998432\n",
      "complete -20.01006696018858\n",
      "apache -19.733290418404714\n",
      "journal -19.300264579876345\n",
      "aulus -18.369604700863206\n",
      "diuk -18.369604700863206\n",
      "santaclaus -18.369604700863206\n",
      "lyteria -17.00692038741852\n",
      "foes -16.623335701576423\n"
     ]
    }
   ],
   "source": [
    "# CODE FOR PROBLEM 1\n",
    "\n",
    "# You'll need to copy over the functions you need: things like \"tokenize\" will \n",
    "# certainly be necessary.\n",
    "\n",
    "# I recommend removing stopwords, but test, and see what happens if you don't.\n",
    "\n",
    "# The column 'reception' has several possible values, including 'elite' (was\n",
    "# reviewed in elite journals), and 'vulgar' (which doesn't mean the poetry was\n",
    "# obscene, but is just a wry way of saying it didn't turn up in our sample of \n",
    "# reviews). You want to contrast these two groups. Leave out other rows, where\n",
    "# 'reception' has a value like 'remove.'\n",
    "\n",
    "# After you've run code to produce the top 25 and bottom 25 words, sorted by \n",
    "# signed Dunnings, write a few sentences of commentary below.\n",
    "\n",
    "poefic.shape\n",
    "\n",
    "poefic.index = range(poefic.shape[0])\n",
    "# print(poefic.index)\n",
    "\n",
    "vocab = create_vocab(poefic['text'], 50000)\n",
    "print('Total vocab = ', len(vocab))\n",
    "\n",
    "unique_vocab = set(vocab)\n",
    "print('Total unique words in vocab =', len(unique_vocab))\n",
    "\n",
    "# An optional step: removing stopwords\n",
    "vocab_no_stop = list(set(vocab) - stopwords)\n",
    "\n",
    "print('Total vocab minus stop words = ', len(vocab_no_stop))\n",
    "\n",
    "# Create counters for the review and not reviewed corpora.\n",
    "\n",
    "review = Counter()\n",
    "noreview = Counter()\n",
    "\n",
    "num_rows = poefic.shape[0]\n",
    "print('Total number of rows in Poefic dataset = ', num_rows)\n",
    "\n",
    "ignored = 0\n",
    "\n",
    "for i in range(num_rows):\n",
    "    counts = tokenize(poefic['text'][i])\n",
    "    if 'elite' in poefic['reception'][i]:\n",
    "        addcounters(counts, review)\n",
    "    if 'vulgar' in poefic['reception'][i]:\n",
    "        addcounters(counts, noreview)\n",
    "    else:\n",
    "        ignored += 1\n",
    "\n",
    "print('Words in ignored texts: '+ str(ignored))\n",
    "\n",
    "review_count = len(review)\n",
    "noreview_count = len(noreview)\n",
    "\n",
    "print('Total words in poems reviewed = ', review_count)\n",
    "print('Total words in poems not reviewed = ', noreview_count)\n",
    "\n",
    "total_poefic_words = Counter()\n",
    "addcounters(review, total_poefic_words)\n",
    "addcounters(noreview, total_poefic_words)\n",
    "\n",
    "print('Total word count = ', len(total_poefic_words))\n",
    "\n",
    "rep_review_words_dunnings = []\n",
    "rep_review_words_nostop_dunnings = []\n",
    "\n",
    "for wrd in vocab:\n",
    "    x = signed_dunnings(review, review_count, noreview, noreview_count, wrd)\n",
    "    rep_review_words_dunnings.append((x, wrd))\n",
    "\n",
    "# print(len(rep_review_words_dunnings))\n",
    "    \n",
    "for wrd in vocab_no_stop:\n",
    "    y = signed_dunnings(review, review_count, noreview, noreview_count, wrd)\n",
    "    rep_review_words_nostop_dunnings.append((y, wrd))\n",
    "\n",
    "# print(len(rep_review_words_nostop_dunnings))\n",
    "\n",
    "print('    '+'FOR DUNNINGS:')\n",
    "headandtail(rep_review_words_dunnings, 25)\n",
    "\n",
    "print('    '+'FOR DUNNINGS, STOP WORDS REMOVED:')\n",
    "headandtail(rep_review_words_nostop_dunnings, 25)\n",
    "\n",
    "# I went ahead and did log analysis as well, as I didn't catch that it wasn't \n",
    "#  asked for specifically until after finishing.\n",
    "\n",
    "# rep_review_words_log = []\n",
    "# rep_review_words_nostop_log = []\n",
    "\n",
    "# for word in vocab:\n",
    "#     z = logodds(review, noreview, word)\n",
    "#     rep_review_words_log.append((z, word))\n",
    "\n",
    "# print(len(rep_review_words_log))\n",
    "    \n",
    "# for word in vocab_no_stop:\n",
    "#     w = logodds(review, noreview, word)\n",
    "#     rep_review_words_nostop_log.append((w, word))\n",
    "\n",
    "# print(len(rep_review_words_nostop_log))\n",
    "    \n",
    "# print('    '+'FOR LOG ODDS:')\n",
    "# headandtail(rep_review_words_log, 25)\n",
    "\n",
    "# print('    '+'FOR LOG ODDS, STOP WORDS REMOVED:')\n",
    "# headandtail(rep_review_words_nostop_log, 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Brief commentary on results.\n",
    "\n",
    "This isn't a class on 19th-century poetry, so I don't expect you to fully\n",
    "interpret the results. (As Clarice was rightly suggesting in class, it's\n",
    "necessary to actually read a few documents before we're in a position to\n",
    "interpret quantitative patterns.) But you might be able to speculate or\n",
    "form tentative hypotheses based on a selection of distinctive words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shallow Analysis\n",
    "Analysis might suggest that Christian texts were not reviewed by elite journals as much as other texts, many of which include characters with non-Christian (or in the case of Dante, non-mainstream Christian) religious characters/themes. In the least likely to appear list we have \"jesus,\" \"saviour\" (admittedly an ambiguous term, with regard to religion), \"prayer,\" and \"herodias.\" This might possibly be one long text throwing off the results, but it's hard to say without an in-depth look at the data. It might make sense to break out this way, if the poetry in the set belongs to hymn or prayer books, which aren't meant for critical review, and are maybe only tenuously classified as fiction, in the traditional sense, at all.\n",
    "\n",
    "Strangely (and interestingly), the white space character is in the top 2 with and without stop words. Perhaps this is a character that should be added to the stop words (possibly, depending on your research questions), but it does seem to imply that poetry with more \"experimental\" line structure--such as poetry with fewer words per line--is overwhelmingly more often reviewed than poetry without. With a closer look at dates and the history of poetry, it might make a lot of sense, if this sort of line structure was more popular at the time. Reviewers tend to put more focus on the artists/work that is in the current trend, or by artists who have worked in that trend, than they do for that outside of current trends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
